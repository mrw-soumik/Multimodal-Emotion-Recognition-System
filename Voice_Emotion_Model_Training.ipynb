{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUdnx8uFuy3Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Paths to datasets\n",
        "RAV_PATH = '/kaggle/input/ravdess-emotional-speech-audio'\n",
        "TESS_PATH = '/kaggle/input/toronto-emotional-speech-set-tess/TESS Toronto emotional speech set data'\n",
        "\n",
        "def load_ravdess_data():\n",
        "    \"\"\"Load and prepare RAVDESS dataset\"\"\"\n",
        "    label_map_ravdess = {\n",
        "        '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',\n",
        "        '05': 'angry', '06': 'fearful', '07': 'disguist', '08': 'surprised'\n",
        "    }\n",
        "\n",
        "    ravdess_file_paths = []\n",
        "    ravdess_labels = []\n",
        "\n",
        "    for actor in os.listdir(RAV_PATH):\n",
        "        actor_path = os.path.join(RAV_PATH, actor)\n",
        "        for file in os.listdir(actor_path):\n",
        "            if file.startswith('0'):\n",
        "                file_path = os.path.join(actor_path, file)\n",
        "                ravdess_file_paths.append(file_path)\n",
        "                emotion = file[6:8]\n",
        "                ravdess_labels.append(label_map_ravdess[emotion])\n",
        "\n",
        "    return pd.DataFrame({'paths': ravdess_file_paths, 'emotions': ravdess_labels})\n",
        "\n",
        "def load_tess_data():\n",
        "    \"\"\"Load and prepare TESS dataset\"\"\"\n",
        "    tess_file_paths = []\n",
        "    tess_labels = []\n",
        "\n",
        "    for folder in os.listdir(TESS_PATH):\n",
        "        folder_path = os.path.join(TESS_PATH, folder)\n",
        "        label = folder[4:].lower()\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            tess_file_paths.append(file_path)\n",
        "            tess_labels.append(label)\n",
        "\n",
        "    df = pd.DataFrame({'paths': tess_file_paths, 'emotions': tess_labels})\n",
        "    df['emotions'] = df['emotions'].replace({\n",
        "        'pleasant_surprise': 'surprised',\n",
        "        'pleasant_surprised': 'surprised',\n",
        "        'fear': 'fearful',\n",
        "        'disgust': 'disguist'\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "def extract_features(file_path):\n",
        "    \"\"\"Extract MEL and MFCC features from audio file\"\"\"\n",
        "    data, sample_rate = librosa.load(file_path)\n",
        "    mel_features = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
        "    mfcc_features = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=13).T, axis=0)\n",
        "    return np.hstack((mel_features, mfcc_features))\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training history metrics\"\"\"\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def clean_emotion_labels(labels):\n",
        "    \"\"\"Remove 'x0_' prefix from emotion labels\"\"\"\n",
        "    return [label.replace('x0_', '') for label in labels]\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, encoder):\n",
        "    \"\"\"Comprehensive model evaluation with clean emotion labels\"\"\"\n",
        "    # Get predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Get emotion labels and clean them\n",
        "    emotion_labels = clean_emotion_labels(encoder.get_feature_names_out())\n",
        "\n",
        "    print(\"\\n=== Model Evaluation ===\")\n",
        "\n",
        "    # 1. Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true_classes, y_pred_classes,\n",
        "                              target_names=emotion_labels,\n",
        "                              digits=3))\n",
        "\n",
        "    # 2. Confusion Matrix\n",
        "    print(\"\\nPlotting Confusion Matrix...\")\n",
        "    plot_confusion_matrix(y_true_classes, y_pred_classes, emotion_labels)\n",
        "\n",
        "    # 3. Per-class Accuracy\n",
        "    print(\"\\nCalculating Per-class Accuracy...\")\n",
        "    accuracies = plot_per_class_accuracy(y_true_classes, y_pred_classes, emotion_labels)\n",
        "\n",
        "    # 4. Print per-class accuracy summary\n",
        "    print(\"\\nPer-class Accuracy Summary:\")\n",
        "    for emotion, acc in zip(emotion_labels, accuracies):\n",
        "        print(f\"{emotion}: {acc:.3f}\")\n",
        "\n",
        "    # 5. Additional metrics\n",
        "    print(\"\\nAdditional Metrics:\")\n",
        "    print(f\"Overall Accuracy: {np.mean(y_true_classes == y_pred_classes):.3f}\")\n",
        "\n",
        "    # Return metrics for saving\n",
        "    return {\n",
        "        'confusion_matrix': confusion_matrix(y_true_classes, y_pred_classes),\n",
        "        'per_class_accuracy': dict(zip(emotion_labels, accuracies)),\n",
        "        'overall_accuracy': np.mean(y_true_classes == y_pred_classes)\n",
        "    }\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels):\n",
        "    \"\"\"Plot confusion matrix with proper labels\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(cm,\n",
        "                xticklabels=labels,\n",
        "                yticklabels=labels,\n",
        "                annot=True,\n",
        "                fmt='d',\n",
        "                cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_per_class_accuracy(y_true, y_pred, labels):\n",
        "    \"\"\"Plot accuracy for each emotion class\"\"\"\n",
        "    # Calculate per-class accuracy\n",
        "    accuracies = []\n",
        "    for i in range(len(labels)):\n",
        "        mask = (y_true == i)\n",
        "        acc = np.mean(y_pred[mask] == y_true[mask])\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=labels, y=accuracies)\n",
        "    plt.title('Per-Class Accuracy')\n",
        "    plt.xlabel('Emotion')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return accuracies\n",
        "\n",
        "def main():\n",
        "    # Create output directory\n",
        "    OUTPUT_DIR = '/kaggle/working/emotion_recognition_export'\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    print(\"Loading datasets...\")\n",
        "    rav_data = load_ravdess_data()\n",
        "    tess_data = load_tess_data()\n",
        "    emotion_data = pd.concat([rav_data, tess_data], axis=0).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nExtracting features...\")\n",
        "    features = []\n",
        "    for i, path in enumerate(emotion_data['paths']):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Processing file {i}/{len(emotion_data)}\")\n",
        "        features.append(extract_features(path))\n",
        "    features = np.array(features)\n",
        "\n",
        "    # Prepare data for training\n",
        "    X = features\n",
        "    y = emotion_data['emotions'].to_numpy()\n",
        "\n",
        "    # Encode labels\n",
        "    encoder = OneHotEncoder()\n",
        "    y_encoded = encoder.fit_transform(y.reshape(-1, 1)).toarray()\n",
        "\n",
        "    # Split and scale data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Reshape for TimeDistributed layer\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "    # Build model\n",
        "    model = Sequential([\n",
        "        TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "                       input_shape=(X_train.shape[1], X_train.shape[2], 1)),\n",
        "        TimeDistributed(MaxPooling1D(pool_size=2)),\n",
        "        TimeDistributed(Flatten()),\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(LSTM(64)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(y_train.shape[1], activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.005),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nTraining model...\")\n",
        "    history = model.fit(X_train, y_train,\n",
        "                       validation_data=(X_test, y_test),\n",
        "                       epochs=150,\n",
        "                       batch_size=32,\n",
        "                       verbose=1)\n",
        "\n",
        "    # Plot training history\n",
        "    print(\"\\nPlotting training history...\")\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"\\nEvaluating model...\")\n",
        "    evaluation_metrics = evaluate_model(model, X_test, y_test, encoder)\n",
        "\n",
        "    # Save everything\n",
        "    print(\"\\nSaving model and artifacts...\")\n",
        "\n",
        "    # 1. Save the model\n",
        "    model.save(os.path.join(OUTPUT_DIR, 'emotion_model.keras'))\n",
        "\n",
        "    # 2. Save the encoder\n",
        "    with open(os.path.join(OUTPUT_DIR, 'encoder.pkl'), 'wb') as f:\n",
        "        pickle.dump(encoder, f)\n",
        "\n",
        "    # 3. Save the scaler\n",
        "    with open(os.path.join(OUTPUT_DIR, 'scaler.pkl'), 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "    # 4. Save model configuration\n",
        "    config = {\n",
        "        'sample_rate': 22050,\n",
        "        'mel_features': 128,\n",
        "        'mfcc_features': 13,\n",
        "        'total_features': 141,\n",
        "        'emotions': list(encoder.get_feature_names_out())\n",
        "    }\n",
        "    with open(os.path.join(OUTPUT_DIR, 'model_config.pkl'), 'wb') as f:\n",
        "        pickle.dump(config, f)\n",
        "\n",
        "    # 5. Save training history\n",
        "    history_dict = {\n",
        "        'accuracy': history.history['accuracy'],\n",
        "        'val_accuracy': history.history['val_accuracy'],\n",
        "        'loss': history.history['loss'],\n",
        "        'val_loss': history.history['val_loss']\n",
        "    }\n",
        "    with open(os.path.join(OUTPUT_DIR, 'training_history.pkl'), 'wb') as f:\n",
        "        pickle.dump(history_dict, f)\n",
        "\n",
        "    # 6. Save evaluation metrics\n",
        "    with open(os.path.join(OUTPUT_DIR, 'evaluation_metrics.pkl'), 'wb') as f:\n",
        "        pickle.dump(evaluation_metrics, f)\n",
        "\n",
        "    print(f\"\\nTraining complete! All files saved to {OUTPUT_DIR}\")\n",
        "    print(\"\\nFiles saved:\")\n",
        "    print(\"1. emotion_model.keras - The trained model\")\n",
        "    print(\"2. encoder.pkl - Label encoder\")\n",
        "    print(\"3. scaler.pkl - Feature scaler\")\n",
        "    print(\"4. model_config.pkl - Model configuration\")\n",
        "    print(\"5. training_history.pkl - Training history\")\n",
        "    print(\"6. evaluation_metrics.pkl - Evaluation metrics\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}