{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTSzcOydtipP"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip, RandomRotation, ColorJitter\n",
        "from timm import create_model\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torch.amp import autocast, GradScaler  # Updated GradScaler\n",
        "\n",
        "# ========================= Configuration =========================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_CLASSES = 7  # FER2013 has 7 emotions\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "FER_TRAIN_DIR = \"/kaggle/input/fer2013/train/\"\n",
        "FER_TEST_DIR = \"/kaggle/input/fer2013/test/\"\n",
        "CLASS_NAMES = [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
        "\n",
        "# ========================= Dataset Preparation =========================\n",
        "class FERDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Collect all image paths and their corresponding labels\n",
        "        for label, class_name in enumerate(CLASS_NAMES):\n",
        "            class_dir = os.path.join(img_dir, class_name)\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                self.image_paths.append(os.path.join(class_dir, img_name))\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")  # Ensure all images are RGB\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# ========================= Transformations =========================\n",
        "train_transform = Compose([\n",
        "    Resize((224, 224)),\n",
        "    RandomHorizontalFlip(p=0.5),\n",
        "    RandomRotation(degrees=10),\n",
        "    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "test_transform = Compose([\n",
        "    Resize((224, 224)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# ========================= Data Loaders =========================\n",
        "train_dataset = FERDataset(img_dir=FER_TRAIN_DIR, transform=train_transform)\n",
        "test_dataset = FERDataset(img_dir=FER_TEST_DIR, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "# ========================= ViT Model =========================\n",
        "class ViTEmotionModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ViTEmotionModel, self).__init__()\n",
        "        self.model = create_model('vit_base_patch16_224', pretrained=True)\n",
        "        self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = ViTEmotionModel(NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "# ========================= Training and Validation Functions =========================\n",
        "def train_one_epoch(model, loader, criterion, optimizer, scaler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    for images, labels in tqdm(loader):\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        with autocast(device_type=\"cuda\"):  # Fixed autocast\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return running_loss / len(loader), accuracy\n",
        "\n",
        "def evaluate_model(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            with autocast(device_type=\"cuda\"):  # Fixed autocast\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return running_loss / len(loader), accuracy, all_labels, all_preds\n",
        "\n",
        "# ========================= Class Weights for Imbalance =========================\n",
        "class_counts = [len(os.listdir(os.path.join(FER_TRAIN_DIR, class_name))) for class_name in CLASS_NAMES]\n",
        "class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float32)\n",
        "class_weights = class_weights.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# ========================= Optimizer and Scheduler =========================\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "scaler = GradScaler()  # Updated to avoid deprecation warning\n",
        "\n",
        "# ========================= Training =========================\n",
        "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, scaler)\n",
        "    val_loss, val_acc, _, _ = evaluate_model(model, test_loader, criterion)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# ========================= Evaluation =========================\n",
        "val_loss, val_acc, val_labels, val_preds = evaluate_model(model, test_loader, criterion)\n",
        "print(f\"Test Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(val_labels, val_preds, target_names=CLASS_NAMES))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(val_labels, val_preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()\n",
        "\n",
        "# ========================= Save Model =========================\n",
        "torch.save(model.state_dict(), \"vit_emotion_model.pth\")"
      ]
    }
  ]
}